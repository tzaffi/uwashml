{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi': 3, 'mom': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = {'hi': 3, 'mom': 4}\n",
    "d2 = { x: d1[x] for x in d1 }\n",
    "d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Using deep features to build an image classifier\n",
    "\n",
    "#Fire up GraphLab Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load a common image analysis dataset\n",
    "\n",
    "We will use a popular benchmark dataset in computer vision called CIFAR-10.  \n",
    "\n",
    "(We've reduced the data to just 4 categories = {'cat','bird','automobile','dog'}.)\n",
    "\n",
    "This dataset is already split into a training set and test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_train = graphlab.SFrame('image_train_data/')\n",
    "image_test = graphlab.SFrame('image_test_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exploring the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#graphlab.canvas.set_target('ipynb')\n",
    "graphlab.canvas.set_target('browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is accessible via web browser at the URL: http://localhost:61512/index.html\n",
      "Opening Canvas in default web browser.\n"
     ]
    }
   ],
   "source": [
    "image_train['image'].show()\n",
    "#image_train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Train a classifier on the raw image pixels\n",
    "\n",
    "We first start by training a classifier on just the raw pixels of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: Logistic regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 1913\n",
      "PROGRESS: Number of classes           : 4\n",
      "PROGRESS: Number of feature columns   : 1\n",
      "PROGRESS: Number of unpacked features : 3072\n",
      "PROGRESS: Number of coefficients    : 9219\n",
      "PROGRESS: Starting L-BFGS\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | 1         | 6        | 0.000026  | 1.513516     | 0.358076          | 0.391304            |\n",
      "PROGRESS: | 2         | 8        | 1.000000  | 2.046751     | 0.430214          | 0.358696            |\n",
      "PROGRESS: | 3         | 9        | 1.000000  | 2.380711     | 0.440669          | 0.358696            |\n",
      "PROGRESS: | 4         | 10       | 1.000000  | 2.760513     | 0.442760          | 0.336957            |\n",
      "PROGRESS: | 5         | 11       | 1.000000  | 3.191160     | 0.430737          | 0.402174            |\n",
      "PROGRESS: | 6         | 13       | 1.000000  | 3.767501     | 0.467329          | 0.369565            |\n",
      "PROGRESS: | 10        | 17       | 1.000000  | 5.093746     | 0.515421          | 0.423913            |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "raw_pixel_model = graphlab.logistic_classifier.create(image_train,target='label',\n",
    "                                              features=['image_array'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Make a prediction with the simple model based on raw pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is updated and available in a tab in the default browser.\n"
     ]
    }
   ],
   "source": [
    "image_test[0:3]['image'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: str\n",
       "Rows: 3\n",
       "['cat', 'automobile', 'cat']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_test[0:3]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: str\n",
       "Rows: 3\n",
       "['bird', 'cat', 'bird']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_pixel_model.predict(image_test[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model makes wrong predictions for all three images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Evaluating raw pixel model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'confusion_matrix': Columns:\n",
      "\ttarget_label\tstr\n",
      "\tpredicted_label\tstr\n",
      "\tcount\tint\n",
      "\n",
      "Rows: 16\n",
      "\n",
      "Data:\n",
      "+--------------+-----------------+-------+\n",
      "| target_label | predicted_label | count |\n",
      "+--------------+-----------------+-------+\n",
      "|     bird     |       dog       |  189  |\n",
      "|     dog      |       cat       |  263  |\n",
      "|     bird     |    automobile   |   73  |\n",
      "|  automobile  |    automobile   |  530  |\n",
      "|     cat      |       dog       |  285  |\n",
      "|     dog      |       dog       |  402  |\n",
      "|     dog      |    automobile   |   55  |\n",
      "|     bird     |       bird      |  566  |\n",
      "|  automobile  |       bird      |  152  |\n",
      "|     bird     |       cat       |  172  |\n",
      "+--------------+-----------------+-------+\n",
      "[16 rows x 3 columns]\n",
      "Note: Only the head of the SFrame is printed.\n",
      "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns., 'accuracy': 0.46925}\n",
      "+--------------+-----------------+-------+\n",
      "| target_label | predicted_label | count |\n",
      "+--------------+-----------------+-------+\n",
      "|     bird     |       dog       |  189  |\n",
      "|     dog      |       cat       |  263  |\n",
      "|     bird     |    automobile   |   73  |\n",
      "|  automobile  |    automobile   |  530  |\n",
      "|     cat      |       dog       |  285  |\n",
      "|     dog      |       dog       |  402  |\n",
      "|     dog      |    automobile   |   55  |\n",
      "|     bird     |       bird      |  566  |\n",
      "|  automobile  |       bird      |  152  |\n",
      "|     bird     |       cat       |  172  |\n",
      "+--------------+-----------------+-------+\n",
      "[16 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_evaluated = raw_pixel_model.evaluate(image_test)\n",
    "print(raw_evaluated)\n",
    "raw_cmatrix = raw_evaluated['confusion_matrix']\n",
    "# for i in range(16):\n",
    "#     raw_row = raw_cmatrix[i]\n",
    "#     print(raw_row)\n",
    "raw_cmatrix.print_rows(num_columns=16) #doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of this model is poor, getting only about 46% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Can we improve the model using deep features\n",
    "\n",
    "We only have 2005 data points, so it is not possible to train a deep neural network effectively with so little data.  Instead, we will use transfer learning: using deep features trained on the full ImageNet dataset, we will train a simple model on this small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2005"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Computing deep features for our images\n",
    "\n",
    "The two lines below allow us to compute deep features.  This computation takes a little while, so we have already computed them and saved the results as a column in the data you loaded. \n",
    "\n",
    "(Note that if you would like to compute such deep features and have a GPU on your machine, you should use the GPU enabled GraphLab Create, which will be significantly faster for this task.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#deep_learning_model = graphlab.load_model('http://s3.amazonaws.com/GraphLab-Datasets/deeplearning/imagenet_model_iter45')\n",
    "#image_train['deep_features'] = deep_learning_model.extract_features(image_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the column deep_features already contains the pre-computed deep features for this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">id</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">label</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">deep_features</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image_array</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">24</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">bird</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.242871761322,<br>1.09545373917, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[73.0, 77.0, 58.0, 71.0,<br>68.0, 50.0, 77.0, 69.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">33</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">cat</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.525087952614, 0.0,<br>0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[7.0, 5.0, 8.0, 7.0, 5.0,<br>8.0, 5.0, 4.0, 6.0, 7.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">36</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">cat</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.566015958786, 0.0,<br>0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[169.0, 122.0, 65.0,<br>131.0, 108.0, 75.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">70</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">dog</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1.12979578972, 0.0, 0.0,<br>0.778194487095, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[154.0, 179.0, 152.0,<br>159.0, 183.0, 157.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">90</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">bird</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1.71786928177, 0.0, 0.0,<br>0.0, 0.0, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[216.0, 195.0, 180.0,<br>201.0, 178.0, 160.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">97</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">automobile</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1.57818555832, 0.0, 0.0,<br>0.0, 0.0, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[33.0, 44.0, 27.0, 29.0,<br>44.0, 31.0, 32.0, 45.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">107</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">dog</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.0, 0.0,<br>0.220677852631, 0.0,  ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[97.0, 51.0, 31.0, 104.0,<br>58.0, 38.0, 107.0, 61.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">121</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">bird</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.0, 0.23753464222, 0.0,<br>0.0, 0.0, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[93.0, 96.0, 88.0, 102.0,<br>106.0, 97.0, 117.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">136</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">automobile</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.0, 0.0, 0.0, 0.0, 0.0,<br>0.0, 7.5737862587, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[35.0, 59.0, 53.0, 36.0,<br>56.0, 56.0, 42.0, 62.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">138</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 32 Width: 32</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">bird</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.658935725689, 0.0,<br>0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[205.0, 193.0, 195.0,<br>200.0, 187.0, 193.0, ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[10 rows x 5 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tid\tint\n",
       "\timage\tImage\n",
       "\tlabel\tstr\n",
       "\tdeep_features\tarray\n",
       "\timage_array\tarray\n",
       "\n",
       "Rows: 10\n",
       "\n",
       "Data:\n",
       "+-----+----------------------+------------+-------------------------------+\n",
       "|  id |        image         |   label    |         deep_features         |\n",
       "+-----+----------------------+------------+-------------------------------+\n",
       "|  24 | Height: 32 Width: 32 |    bird    | [0.242871761322, 1.0954537... |\n",
       "|  33 | Height: 32 Width: 32 |    cat     | [0.525087952614, 0.0, 0.0,... |\n",
       "|  36 | Height: 32 Width: 32 |    cat     | [0.566015958786, 0.0, 0.0,... |\n",
       "|  70 | Height: 32 Width: 32 |    dog     | [1.12979578972, 0.0, 0.0, ... |\n",
       "|  90 | Height: 32 Width: 32 |    bird    | [1.71786928177, 0.0, 0.0, ... |\n",
       "|  97 | Height: 32 Width: 32 | automobile | [1.57818555832, 0.0, 0.0, ... |\n",
       "| 107 | Height: 32 Width: 32 |    dog     | [0.0, 0.0, 0.220677852631,... |\n",
       "| 121 | Height: 32 Width: 32 |    bird    | [0.0, 0.23753464222, 0.0, ... |\n",
       "| 136 | Height: 32 Width: 32 | automobile | [0.0, 0.0, 0.0, 0.0, 0.0, ... |\n",
       "| 138 | Height: 32 Width: 32 |    bird    | [0.658935725689, 0.0, 0.0,... |\n",
       "+-----+----------------------+------------+-------------------------------+\n",
       "+-------------------------------+\n",
       "|          image_array          |\n",
       "+-------------------------------+\n",
       "| [73.0, 77.0, 58.0, 71.0, 6... |\n",
       "| [7.0, 5.0, 8.0, 7.0, 5.0, ... |\n",
       "| [169.0, 122.0, 65.0, 131.0... |\n",
       "| [154.0, 179.0, 152.0, 159.... |\n",
       "| [216.0, 195.0, 180.0, 201.... |\n",
       "| [33.0, 44.0, 27.0, 29.0, 4... |\n",
       "| [97.0, 51.0, 31.0, 104.0, ... |\n",
       "| [93.0, 96.0, 88.0, 102.0, ... |\n",
       "| [35.0, 59.0, 53.0, 36.0, 5... |\n",
       "| [205.0, 193.0, 195.0, 200.... |\n",
       "+-------------------------------+\n",
       "[10 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_train['deep_features'][0])\n",
    "# wow, 2**6 X 2**6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Given the deep features, let's train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: WARNING: Detected extremely low variance for feature(s) 'deep_features' because all entries are nearly the same.\n",
      "Proceeding with model training using all features. If the model does not provide results of adequate quality, exclude the above mentioned feature(s) from the input dataset.\n",
      "PROGRESS: Logistic regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 1905\n",
      "PROGRESS: Number of classes           : 4\n",
      "PROGRESS: Number of feature columns   : 1\n",
      "PROGRESS: Number of unpacked features : 4096\n",
      "PROGRESS: Number of coefficients    : 12291\n",
      "PROGRESS: Starting L-BFGS\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | 1         | 5        | 0.000131  | 1.565959     | 0.758005          | 0.770000            |\n",
      "PROGRESS: | 2         | 9        | 0.250000  | 3.065893     | 0.765354          | 0.680000            |\n",
      "PROGRESS: | 3         | 10       | 0.250000  | 3.553128     | 0.770079          | 0.700000            |\n",
      "PROGRESS: | 4         | 11       | 0.250000  | 4.074964     | 0.774278          | 0.720000            |\n",
      "PROGRESS: | 5         | 12       | 0.250000  | 4.574684     | 0.779003          | 0.720000            |\n",
      "PROGRESS: | 6         | 13       | 0.250000  | 5.061999     | 0.791076          | 0.720000            |\n",
      "PROGRESS: | 10        | 17       | 0.250000  | 7.105383     | 0.858268          | 0.740000            |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "deep_features_model = graphlab.logistic_classifier.create(image_train,\n",
    "                                                         features=['deep_features'],\n",
    "                                                         target='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Apply the deep features model to first few images of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is updated and available in a tab in the default browser.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype: str\n",
       "Rows: 3\n",
       "['cat', 'automobile', 'cat']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_test[0:3]['image'].show()\n",
    "image_test[0:3]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: str\n",
       "Rows: 3\n",
       "['cat', 'automobile', 'cat']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_features_model.predict(image_test[0:3])\n",
    "# PERFECTO!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier with deep features gets all of these images right!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Compute test_data accuracy of deep_features_model\n",
    "\n",
    "As we can see, deep features provide us with significantly better accuracy (about 78%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.78925, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tstr\n",
       " \tpredicted_label\tstr\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 16\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |     dog      |       cat       |  215  |\n",
       " |     cat      |       cat       |  677  |\n",
       " |  automobile  |       dog       |   5   |\n",
       " |     cat      |    automobile   |   40  |\n",
       " |     dog      |       bird      |   49  |\n",
       " |     cat      |       bird      |   81  |\n",
       " |     bird     |       dog       |   54  |\n",
       " |     cat      |       dog       |  202  |\n",
       " |     dog      |       dog       |  716  |\n",
       " |     dog      |    automobile   |   20  |\n",
       " +--------------+-----------------+-------+\n",
       " [16 rows x 3 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_features_model.evaluate(image_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
